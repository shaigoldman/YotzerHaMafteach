{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# my stuff\n",
    "import LoadSamples\n",
    "from SeferNames import all_sfarim, shas, add_alt_chkchk\n",
    "from SeferNames import cheleks, simans, siifs, sifkatans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_mekor_str=40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names of notes seperators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simanim = np.asarray([[f'I{x}.', f'{x}.', f'{x}I.', f'{x}II.', f'{x}III.'] \n",
    "                      for x in ['I', 'V', 'X', 'XV']]).flatten().tolist()\n",
    "simanim.append('XIV.')\n",
    "simanim.insert(4, 'נספח')\n",
    "\n",
    "sifim = [f'{x}.' for x in 'אבגדהוזחטי']\n",
    "sifim.extend([f'י{x}.' for x in 'אבגדזחט'])\n",
    "sifim.extend([f'ט{x}.' for x in 'וז'])\n",
    "sifim.extend([f'כ{x}.' for x in ' אבגדהוזחט'])\n",
    "\n",
    "klalim = [f'כלל {כ}' for כ in 'אבגדהוזחטי']\n",
    "klalim.extend([f'כלל י{כ}' for כ in 'אבגד'])\n",
    "klalim.extend([f'כלל ט{כ}' for כ in 'וז'])\n",
    "klalim.extend([f'כלל י{כ}' for כ in 'זחט'])\n",
    "klalim.extend([f'כלל כ{כ}' for כ in ' אבגדהוזחט'])\n",
    "\n",
    "while len(simanim) < len(klalim):\n",
    "    simanim.append(simanim[-1])\n",
    "simanim = np.asarray(simanim)\n",
    "simanim = simanim[np.argsort([len(siman) for siman in simanim])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to deal with chuck_chucks and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_chucks(hebrew_word):\n",
    "    for chuck in ['״', '׳', '\"', \"'\"]:\n",
    "        while chuck in hebrew_word:\n",
    "            hebrew_word = (hebrew_word[:hebrew_word.index(chuck)] \n",
    "                           + hebrew_word[hebrew_word.index(chuck)+1:])\n",
    "    return hebrew_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chuck_with(word, prefix):\n",
    "    word = remove_chucks(word)\n",
    "    word = prefix + word\n",
    "    word = word[:-1] + '״' + word[-1]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_chuck(word):\n",
    "    return (\"'\" in word\n",
    "            or '\"' in word\n",
    "            or '״' in word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_be_prefix(letter, place):\n",
    "    first_only = 'בכמלו'\n",
    "    can_be_seconds = 'השד'\n",
    "    if place <=2 and letter in can_be_seconds:\n",
    "        return True\n",
    "    elif place == 1 and letter in first_only:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(hebrew_word, allow_prefix=False, fifty_cap=False,\n",
    "               allow_hundreds=True):\n",
    "    ones = 'אבגדהוזחט'\n",
    "    tens = 'יכלמנסעפצ'\n",
    "    hundreds = 'קרשת'\n",
    "    if fifty_cap:\n",
    "        tens = 'יכלמנ'\n",
    "        allow_hundreds=False\n",
    "    hebrew_word = remove_chucks(hebrew_word)\n",
    "    current_place = 100\n",
    "    prev_letter = 'ת'\n",
    "    for index, letter in enumerate(hebrew_word):\n",
    "        if allow_prefix and can_be_prefix(letter, index+1):\n",
    "            continue\n",
    "        elif letter in hundreds:\n",
    "            if not allow_hundreds:\n",
    "                return False\n",
    "            elif current_place <= 100:\n",
    "                return False\n",
    "            elif hundreds.index(prev_letter) < hundreds.index(letter):\n",
    "                return False\n",
    "            elif (hundreds.index(prev_letter) == hundreds.index(letter)\n",
    "                  and letter != 'ת'):\n",
    "                return False\n",
    "        elif letter in tens:\n",
    "            if current_place <= 10:\n",
    "                return False\n",
    "            current_place = 10\n",
    "        elif letter in ones:\n",
    "            if current_place <= 1:\n",
    "                return False\n",
    "            current_place = 1\n",
    "        else:\n",
    "            return False\n",
    "        prev_letter = letter\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pref(h_str, allowed='מבו'):\n",
    "    if h_str[0] == 'ו':\n",
    "        h_str = h_str[1:]\n",
    "    if h_str[0] in allowed:\n",
    "        h_str = h_str[1:]\n",
    "    return h_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the daf identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amud_str(amud):\n",
    "    if amud == 'א':\n",
    "        return '.'\n",
    "    elif amud == 'ב':\n",
    "        return ':'\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dafs(mekor_str):\n",
    "    words = mekor_str.split(' ')\n",
    "    dafs = []\n",
    "    pairs = []\n",
    "    if 'דף' in words:\n",
    "        # prob form of דף ה עמוד ב, etc\n",
    "        where = words.index('דף')\n",
    "        \n",
    "    for index, word in enumerate(words):\n",
    "        if word == 'דף':\n",
    "            dafs.append(remove_chucks(words[index+1]))\n",
    "        elif word == 'עמוד':\n",
    "            amud = get_amud_str(words[index+1])\n",
    "            if dafs and amud != '':\n",
    "                pairs.append(dafs.pop()+amud)\n",
    "        elif 'ע״' in word or ('ע' + '\"') in word:\n",
    "            amud = get_amud_str(word[-1])\n",
    "            if amud == '':\n",
    "                continue\n",
    "            daf = words[index-1]\n",
    "            if 'ד' in daf and ('״' in daf or '\"' in daf):\n",
    "                daf = daf[1:]\n",
    "            pairs.append(remove_chucks(daf)+amud)\n",
    "    for lonely_daf in dafs:\n",
    "        pairs.append(lonely_daf)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rambam identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rambam_perk_halacha(mekor_str):\n",
    "    words = mekor_str.split(' ')\n",
    "    pereks = []\n",
    "    pairs = []\n",
    "    \n",
    "    for index, word in enumerate(words):\n",
    "        if ('״' in word or '\"' in word):\n",
    "            cut = remove_pref(word, allowed='מבו')\n",
    "            if cut[0] == 'פ':\n",
    "                cut = remove_pref(cut, allowed='פ')\n",
    "                if is_numeric(cut, fifty_cap=True):\n",
    "                    pereks.append(chuck_with(cut, 'פ'))\n",
    "            if cut[0] == 'ה': \n",
    "                cut = remove_pref(cut, allowed='ה')\n",
    "                if is_numeric(cut, fifty_cap=True):\n",
    "                    halacha = chuck_with(cut, 'ה')\n",
    "                    if pereks:\n",
    "                        pairs.append(f'{pereks.pop()} {halacha}')\n",
    "        elif word == 'פרק':\n",
    "            pereks.append(words[index+1])\n",
    "        elif word == 'הלכה':\n",
    "            halacha = words[index+1]\n",
    "            if pereks:\n",
    "                pairs.append(f'{pereks.pop()}:{halacha}')\n",
    "        \n",
    "    for lonely_perek in pereks:\n",
    "        pairs.append(lonely_perek)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutim identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shutim_section(mekor_str):\n",
    "    \n",
    "    if len(mekor_str) > long_mekor_str:\n",
    "        return '?'\n",
    "    \n",
    "    sect_str = ''\n",
    "    words = mekor_str.split(' ')\n",
    "    for index, word in enumerate(words):\n",
    "        for sign in [*cheleks, *simans, *siifs, *sifkatans]:\n",
    "            if sign in word:\n",
    "                if sign == 'סעיף' and words[index+1] == 'קטן':\n",
    "                    word = 'סעיף קטן'\n",
    "                    index += 1\n",
    "                if sect_str:\n",
    "                    sect_str += ' '\n",
    "                sect_str += word\n",
    "                if not has_chuck(word) or sign in sifkatans:\n",
    "                    sect_str += ' '\n",
    "                    sect_str += words[index+1]\n",
    "    return sect_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turim identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tur_is_really_a_shut(mekor_str, tur_str):\n",
    "    for shut in all_sfarim['shutim']:\n",
    "        if (shut in mekor_str and np.abs(\n",
    "             mekor_str.index(shut) -  mekor_str.index(tur_str)) < 30):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sefer_name(mekor_str):\n",
    "    \n",
    "    # this is a basic inconsistency i have that should be fixed\n",
    "    mekor_str = mekor_str.replace('השגת', 'השגות')\n",
    "    \n",
    "    for label, sefer_names in all_sfarim.items():\n",
    "        for sefer in sefer_names:\n",
    "             if sefer in mekor_str:\n",
    "                if label == 'sfarim_chizonim':\n",
    "                    return sefer\n",
    "                elif label == 'turim':\n",
    "                    if tur_is_really_a_shut(mekor_str, sefer):\n",
    "                        continue\n",
    "                    return mekor_str[:mekor_str.index(sefer)]\n",
    "                elif label == 'shutim':\n",
    "                    for sectioner in [*cheleks, *simans]:\n",
    "                        if sectioner in mekor_str:\n",
    "                            return mekor_str[:mekor_str.index(sectioner)]\n",
    "                elif label == 'rambam':\n",
    "                    for halacha_str in [' הלכות ',\"הל' \", 'הל׳',]:\n",
    "                        if halacha_str in mekor_str:\n",
    "                            mekor_str = mekor_str.replace(halacha_str, '')\n",
    "                    return mekor_str[:mekor_str.index(sefer)]\n",
    "                elif label == 'mesechtot':\n",
    "                    if 'מסכת' in mekor_str:\n",
    "                        name = mekor_str[:mekor_str.index('מסכת')]\n",
    "                    elif sefer == mekor_str.split(' ')[0]:\n",
    "                        name = 'תלמוד בבלי'\n",
    "                    else:\n",
    "                        name = mekor_str[:mekor_str.index(sefer)]\n",
    "                    if 'תלמוד בבלי' in name:\n",
    "                        name = 'גמרא'\n",
    "                    if 'חידושי' in name:\n",
    "                        name = name.replace('חידושי ה', '')\n",
    "                    return name\n",
    "    return '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gematria(letters_str):\n",
    "    value = 0\n",
    "    ones = 'אבגדהוזחט'\n",
    "    for ot in ones:\n",
    "        if ot in letters_str:\n",
    "            value += (ones.index(ot)+1)\n",
    "    tens = 'יכלמנסעפצ'\n",
    "    for ot in tens:\n",
    "        if ot in letters_str:\n",
    "            value += (tens.index(ot)+1) * 10\n",
    "    hunds = 'קרשת'\n",
    "    for ot in hunds:\n",
    "        if ot in letters_str:\n",
    "            value += (hunds.index(ot)+1) * 100\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daf_numerical(daf_str):\n",
    "    value = gematria(daf_str)\n",
    "    if ':' in daf_str:\n",
    "        value += .5\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perek_halacha_numerical(ph_str):\n",
    "    if ':' in ph_str:\n",
    "        perek, halacha = ph_str.split(':') \n",
    "    else:\n",
    "        perek = ph_str\n",
    "        halacha = ''\n",
    "    perek_value = gematria(perek)\n",
    "    halacha_value = gematria(halacha)\n",
    "    total_value = perek_value + halacha_value/100.\n",
    "    return total_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(these_sfarim, priorities):\n",
    "\n",
    "    order = np.argsort(priorities)\n",
    "    these_sfarim = these_sfarim.iloc[order]\n",
    "    \n",
    "    # put ordering into big df\n",
    "    indicies = these_sfarim.index\n",
    "    these_sfarim.index = range(len(these_sfarim))\n",
    "    return these_sfarim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summed_priorities(*priorities):\n",
    "    summed_priority = np.zeros(len(priorities[0]))\n",
    "    multiplier = 100 ** (len(priorities)-1)\n",
    "    for priority in priorities:\n",
    "        priority = np.asarray(priority)\n",
    "        summed_priority += priority*multiplier\n",
    "        multiplier /= 100\n",
    "    return summed_priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klal_siman_sif_priority(mekorot_df):\n",
    "    \n",
    "    klalim_order = np.array(\n",
    "        [klalim.index(klal) for klal in mesechets['klal']])\n",
    "    \n",
    "    simanim_order = np.array(\n",
    "        [klalim.index(siman) for siman in mesechets['siman']])\n",
    "    \n",
    "    sifim_order = np.array(\n",
    "        [klalim.index(siman) for siman in mesechets['sif']])\n",
    "    \n",
    "    return (klalim_order, simanim_order, sifim_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_shas(mekorot_df):\n",
    "    # get the mesechets out of the big df\n",
    "    mesechets = mekorot_df[mekorot_df['type'] == 'mesechtot']\n",
    "    \n",
    "    # order by order of shas\n",
    "    mesechets_order = np.array(\n",
    "        [shas.index(section) for section in mesechets['section']])\n",
    "    \n",
    "    # put the commentaries on the rif in the back\n",
    "    rif_commentaries = ['ר״ן על', 'ספר הזכות', 'מלחמת', 'כתוב שם', 'המאור', 'רי״ף']\n",
    "    add_alt_chkchk(rif_commentaries)\n",
    "    rif_priority = np.array(\n",
    "        [len(rif_commentaries) -\n",
    "          [*[rishon in sefer for rishon in rif_commentaries], \n",
    "            True].index(True)\n",
    "         for sefer in mesechets['sefer']])\n",
    "    \n",
    "    # order by daf\n",
    "    daf_order = np.array(\n",
    "        [daf_numerical(daf_str) for daf_str in mesechets['where']])\n",
    "    \n",
    "    # order gemara first then commentaries\n",
    "    gemara_first_priority = np.array(\n",
    "        [sefer != 'גמרא' for sefer in mesechets['sefer']]).astype(int)\n",
    "    \n",
    "    # order some of the main commentaries first\n",
    "    main_rishonim = ['רש״י', 'תוס', 'רמב״ן', 'רשב״א', 'ריטב״א']\n",
    "    add_alt_chkchk(main_rishonim)\n",
    "    rishonim_priority = np.array(\n",
    "        [[*[rishon in sefer for rishon in main_rishonim], \n",
    "            True].index(True)\n",
    "         for sefer in mesechets['sefer']])\n",
    "    \n",
    "    # alphabetize to group commentaries with same name\n",
    "    # -> helpful for sorting תוס ראש  and other תוס and such\n",
    "    a_sorted = np.sort(mesechets['sefer']).tolist()\n",
    "    alphabetical_priority = np.array(\n",
    "                [a_sorted.index(sefer) for sefer in mesechets['sefer']])\n",
    "    \n",
    "    \n",
    "    summed_priorities = get_summed_priorities(\n",
    "        mesechets_order, rif_priority,\n",
    "        daf_order, gemara_first_priority,\n",
    "        rishonim_priority, alphabetical_priority\n",
    "    )\n",
    "    \n",
    "    return reorder(mesechets, summed_priorities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_rambam(mekorot_df):\n",
    "    \n",
    "    rambams = mekorot_df[mekorot_df['type'] == 'rambam']\n",
    "    \n",
    "    \n",
    "    # order by section\n",
    "    halachas_order = np.array(\n",
    "        [all_sfarim['rambam'].index(section) for section in rambams['section']]) * 100\n",
    "    \n",
    "    # order by perek halacha\n",
    "    halacha_priority = np.array(\n",
    "                [perek_halacha_numerical(where) for where in rambams['where']]) * 100\n",
    "    \n",
    "    # known ordering of sfarim\n",
    "    known_sfarim = ['רמב״ם', 'השגות הראב״ד',\n",
    "                    'מגיד משנה', 'מ״מ', 'כסף משנה', 'כס״מ',\n",
    "                    'משנה למלך',\n",
    "                   ]\n",
    "    add_alt_chkchk(known_sfarim)\n",
    "    known_priority = np.array(\n",
    "        [[*[sf in sefer for sf in known_sfarim], \n",
    "            True].index(True)\n",
    "         for sefer in rambams['sefer']])\n",
    "    \n",
    "    # alphabetize to group commentaries with same name\n",
    "    a_sorted = np.sort(rambams['sefer']).tolist()\n",
    "    alphabetical_priority = np.array(\n",
    "                [a_sorted.index(sefer) for sefer in rambams['sefer']])\n",
    "     \n",
    "    summed_priorities = get_summed_priorities(\n",
    "        halachas_order, halacha_priority, known_priority, alphabetical_priority\n",
    "    )\n",
    "    \n",
    "    return reorder(rambams, summed_priorities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_section(mekorot_df, typ):\n",
    "    if typ == 'mesechtot':\n",
    "        return sort_shas(mekorot_df)\n",
    "    elif typ == 'rambam':\n",
    "        return sort_rambam(mekorot_df)\n",
    "    # get the section out of the big df\n",
    "    these_sfarim = mekorot_df[mekorot_df['type'] == typ]\n",
    "    \n",
    "    # alphabetize to group commentaries with same name\n",
    "    a_sorted = np.sort(these_sfarim['sefer']).tolist()\n",
    "    alphabetical_priority = np.array(\n",
    "                [a_sorted.index(sefer) for sefer in these_sfarim['sefer']])\n",
    "    \n",
    "    return reorder(these_sfarim, alphabetical_priority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mafteach Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mafteach(text):\n",
    "    \"\"\" Builds a Mafteach based on the given hebrew text.\n",
    "    \n",
    "        Args:\n",
    "            text (list of str): List of strings where each\n",
    "                item is a line of text.\n",
    "        \n",
    "        Returns:\n",
    "            list of pd.DataFrames, each including a different\n",
    "            kind of mafteach.\n",
    "    \"\"\"\n",
    "    #------Variables for the tracking\n",
    "    this_klal = None\n",
    "    this_siman = None\n",
    "    this_sif = None\n",
    "    mekorot = []\n",
    "    #-------Find the mekorot\n",
    "    for line in text:\n",
    "        #------Check if it is a new klal, siman or sif\n",
    "        for klal in klalim:\n",
    "            if klal in line:\n",
    "                if (len(line) <= line.index(klal)+len(klal)\n",
    "                        or line[line.index(klal)+len(klal)] == '.'):\n",
    "                    this_klal = klal\n",
    "        for siman in simanim:\n",
    "            if siman in line:\n",
    "                if '.' in siman:\n",
    "                    siman = siman[:-1]\n",
    "                this_siman = siman # take off the period\n",
    "                this_sif = '-'\n",
    "                \n",
    "        for sif in sifim:\n",
    "            if sif in line and len(line)<50:\n",
    "                this_sif = sif[:-1] # take off the period\n",
    "                \n",
    "        if len(line) > long_mekor_str:\n",
    "            continue\n",
    "        #------Check if there is a mekor here\n",
    "        for label, sefer_names in all_sfarim.items():\n",
    "            # ^ \"sefer_names\" is not a super accurate variable descript\n",
    "            #   unfortunately, because for example חידושי הריטב״א סוכה is \n",
    "            #   being identified under the \"sefer_name\" סוכה with this alg.\n",
    "            for sefer in sefer_names:\n",
    "                if sefer in line:\n",
    "                    \n",
    "                    where = ['']\n",
    "                    section = []\n",
    "                    \n",
    "                    if label == 'mesechtot':\n",
    "                        where = get_dafs(line)\n",
    "                        if where == ['']:\n",
    "                            # This is probably not a real mekor, just the notes\n",
    "                            # mention something general about מסכת מעילה etc.\n",
    "                            continue\n",
    "                        section = sefer#sefer[sefer.index(' ')+1:]\n",
    "                    if label == 'rambam':\n",
    "                        where = rambam_perk_halacha(line)\n",
    "                        section = sefer\n",
    "                    elif label == 'turim':\n",
    "                        if tur_is_really_a_shut(line, sefer):\n",
    "                            continue\n",
    "                    elif label == 'shutim':\n",
    "                        where = shutim_section(line)\n",
    "                    elif label == 'sfarim_chizonim':\n",
    "                        shut_sect = shutim_section(line)\n",
    "                        if shut_sect:\n",
    "                            where = shut_sect\n",
    "                        else:\n",
    "                            where = line[line.index(sefer)+len(sefer)+1:]\n",
    "                    \n",
    "                    text_start = line.index(sefer) - 15\n",
    "                    if text_start < 0: text_start = 0\n",
    "                    text = line[text_start:line.index(sefer) + 35]\n",
    "                    \n",
    "                    sefer_name = get_sefer_name(line).replace('״', '\"')\n",
    "                    while len(sefer_name)>1 and sefer_name[-1] == ' ':\n",
    "                        sefer_name = sefer_name[:-1]\n",
    "                    \n",
    "                    if type(where) != list: where = [where]\n",
    "                    if type(section) != list: section = [section]\n",
    "                    while len(section) < len(where):\n",
    "                        section.append('')\n",
    "                    \n",
    "                    for w, s in zip(where, section):\n",
    "                        mekor = pd.DataFrame({\n",
    "                                    'text': [text], 'type': [label],\n",
    "                                    'sefer': [sefer_name],\n",
    "                                    'section': [s],\n",
    "                                    'klal': [this_klal], 'siman': [this_siman],\n",
    "                                    'sif': [this_sif],\n",
    "                                    'where': [w]})\n",
    "                        mekorot.append(mekor)\n",
    "    #-------Turn it into a DataFrame\n",
    "    key = pd.concat(mekorot)\n",
    "    key.index = range(len(key))\n",
    "    #-------Sort\n",
    "    type_sort = np.argsort([list(all_sfarim.keys()).index(typ) for typ in key['type']])\n",
    "    key = key.loc[type_sort]\n",
    "    key.index = range(len(key))\n",
    "    \n",
    "    keys = []\n",
    "    for typ in key['type'].unique():\n",
    "        keys.append(sort_section(key, typ))\n",
    "    \n",
    "    for key_num, key in enumerate(keys):\n",
    "        keys[key_num] = key[['sif', 'siman', 'klal', 'sefer', 'where', 'section', 'type']]\n",
    "        # blank repeated refrences\n",
    "        for rownum, (index, row) in enumerate(keys[key_num].iterrows()):\n",
    "            row = row[['klal', 'siman', 'sif', 'sefer', 'where', 'section']]\n",
    "            for label, item in row.iteritems():\n",
    "                go_backs = 1\n",
    "                while rownum-go_backs>0 and keys[key_num].iloc[rownum-go_backs][label] == '':\n",
    "                    go_backs += 1\n",
    "                \n",
    "                if (rownum-go_backs>=0 \n",
    "                    and (item == keys[key_num].iloc[rownum-go_backs][label])\n",
    "                    and item != '-'):\n",
    "                    # dont blank repeat siman/sif unless \n",
    "                    # its a repeat klal etc\n",
    "                    if label == 'siman' or label == 'sif':\n",
    "                        if not keys[key_num].loc[index, 'klal'] == '':\n",
    "                            continue\n",
    "                    if label == 'sif':\n",
    "                        if not keys[key_num].loc[index, 'siman'] == '':\n",
    "                            continue\n",
    "                    # do the blanking\n",
    "                    keys[key_num].loc[index, label] = ''      \n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mafteach(keys, savename='mafteach.xlsx'):\n",
    "    \"\"\"\" Saves the outputted Mafteach from build_mafteach to an xcel sheet.\"\"\"\n",
    "    with pd.ExcelWriter('mafteach.xlsx') as writer:\n",
    "        for key in keys:\n",
    "            typ = key.pop('type').unique()[0]\n",
    "            key.to_excel(excel_writer=writer, sheet_name=typ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lumdusislife/anaconda3/envs/py3_env/lib/python3.6/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/lumdusislife/anaconda3/envs/py3_env/lib/python3.6/site-packages/ipykernel_launcher.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    text = LoadSamples.load_sample(1)\n",
    "    keys = build_mafteach(text)\n",
    "    save_mafteach(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_env",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
